from datetime import datetime

import openpyxl
from bs4 import BeautifulSoup
import urllib.request
import pickle
import re

def creatwb(wbname):
    wb=openpyxl.Workbook()
    wb.save(filename=wbname)
    print ("新建Excel："+wbname+"成功")

# 写入excel文件中 date 数据，date是list数据类型， fields 表头
def savetoexcel(data,fields,sheetname,wbname):
    print("写入excel：")
    wb=openpyxl.load_workbook(filename=wbname)

    try:
        sheet = wb.get_sheet_by_name(sheetname)
    except:
        sheet = wb.create_sheet(sheetname)

    if  sheet.max_row<=1:
        for field in range(1,len(fields)+1):   # 写入表头
                _=sheet.cell(row=1,column=field,value=str(fields[field-1]))

    maxrow=sheet.max_row
    col1=0
    for row1 in range(maxrow+1,maxrow+len(data)+1):  # 写入数据
        for col1 in range(1,len(data[row1-maxrow-2])+1):
            _=sheet.cell(row=row1,column=col1,value=str(data[row1-maxrow-2][col1-1]))

    wb.save(filename=wbname)
    print("保存成功")

urls = ["http://yuedu.163.com/search.do?operation=exact&kind=partner&type=4&word=8986194&sortType=new&page={:02d}".format(x) for x in range(1,36)]
try:
    f = open('result.xlsx','rb')
    f.close()
except:
    creatwb('result.xlsx')

booklist=[]
for url in urls:
    html = urllib.request.urlopen(url)
    bsobj = BeautifulSoup(html, 'lxml')
    #rp = re.compile(self.replace)  # 'nbs.*$')
    #creatwb("result.xlsx")

    try:
        f = open('urlset.db','rb')
        urlset = pickle.load(f)
        f.close()
    except:
        urlset = set()


    for book in bsobj.select(".yd-book-item"):  # '#titleList a'):
        name = book.select("h2")[0].get_text().strip()
        author = book.select("dd")[0].get_text()
        url = book.select("a")[0].attrs['href']
        summery = book.select(".summery")[0].get_text().strip()
        if url not in urlset:
            print('add',url)
            urlset.add(url)
            booklist.append((name,author,summery))

    print(urlset)
    try:
        f = open('urlset.db','wb')
        pickle.dump(urlset,f)
        f.close()
    except:
        print('save urlset failed')


if  len(booklist):
    savetoexcel(booklist,['书名','作者','简介'],datetime.now().strftime("%m-%d-%H-%M")+"新增" '','result.xlsx')
    savetoexcel(booklist,['书名','作者','简介'],'all' ,'result.xlsx')
    print("new book",name,author,'\n')
    # logging.info('extract %s' % url)
#   self.contenturls.append(rp.sub(link['href'], url))

    print('hello,world')
